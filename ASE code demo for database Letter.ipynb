{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示：当前环境 pandas 版本高于 0.25，get_price 与 get_fundamentals_continuously 接口 panel 参数将固定为 False\n",
      "注意：0.25 以上版本 pandas 不支持 panel，如使用该数据结构和相关函数请注意修改\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jqdatasdk import *\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.ensemble as se\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import imblearn.over_sampling as imos\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.copod import COPOD\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "from imbalanced_ensemble.ensemble import SelfPacedEnsembleClassifier\n",
    "from imbalanced_ensemble.ensemble import EasyEnsembleClassifier\n",
    "from imbalanced_ensemble.ensemble import BalanceCascadeClassifier\n",
    "from imbalanced_ensemble.ensemble import RUSBoostClassifier\n",
    "from imbalanced_ensemble.ensemble import SMOTEBoostClassifier\n",
    "from imbalanced_ensemble.ensemble import UnderBaggingClassifier\n",
    "from imbalanced_ensemble.ensemble import OverBaggingClassifier\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "import smote_variants as sv\n",
    "from imblearn.datasets import fetch_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({-1: 3541, 1: 231})\n"
     ]
    }
   ],
   "source": [
    "protein_homo = fetch_datasets()[\"thyroid_sick\"]\n",
    "X, y = protein_homo.data, protein_homo.target\n",
    "X = pd.DataFrame(X)\n",
    "y  = pd.DataFrame(y)\n",
    "y.columns = [\"Class\"]\n",
    "data = pd.concat([X,y],axis=1)\n",
    "\n",
    "\n",
    "# for i in data.columns.values.tolist():\n",
    "#     mean = data[i].mean()\n",
    "#     data[i][data[i].isnull()] = mean\n",
    "\n",
    "negative_data = data.where(data['Class'] == 1).dropna()\n",
    "positive_data = data.where(data['Class'] == -1).dropna()\n",
    "\n",
    "data_labels = data[['Class']]\n",
    "data_features = data.drop(columns=['Class'])\n",
    "\n",
    "\n",
    "tmp = data_labels.values.tolist()\n",
    "tmp = np.ravel(tmp)\n",
    "print('Original dataset shape %s' % Counter(tmp))\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    data_features, data_labels, test_size=0.2)\n",
    "\n",
    "\n",
    "train_features_res, train_labels_res = SMOTE().fit_resample(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators = 50\n",
    "models = []\n",
    "weights = []\n",
    "for i in range (0,n_estimators+1):\n",
    "    clf_name = 'iforest'\n",
    "\n",
    "    c = 0.05 + 0.35*(i/n_estimators)\n",
    "    dis = []\n",
    "    for j in range(0,5):\n",
    "        dis.append(1/abs(j/5-1/20-(1-c)))\n",
    "\n",
    "    clf = IForest(contamination = c) # 初始化检测器clf\n",
    "    clf.fit(train_features) # 使用X_train训练检测器clf \n",
    "    y_train_pred = clf.labels_  # 返回训练数据上的分类标签 (0: 正常值, 1: 异常值)\n",
    "    y_train_scores = clf.decision_scores_  # 返回训练数据上的异常值 (分值越大越异常)\n",
    "\n",
    "\n",
    "    num_out = 0\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    tmp_train_labels = train_labels.values.tolist()\n",
    "    for j in range(0,len(y_train_pred)):\n",
    "        if tmp_train_labels[j][0] - y_train_pred[j] == 1:\n",
    "            num_out += 1\n",
    "        if tmp_train_labels[j][0] == -1 and y_train_pred[j] == 1:\n",
    "            num_neg += 1\n",
    "        if tmp_train_labels[j][0] == 1 and y_train_pred[j] == 1:\n",
    "            num_pos += 1\n",
    "        \n",
    "    if num_neg == 0:\n",
    "        num_neg += 1\n",
    "    if num_pos == 0:\n",
    "        num_pos += 1\n",
    "    #print(num_out)\n",
    "    snr = math.log(negative_data.shape[0]/num_out+1)\n",
    "    #print(snr)\n",
    "    \n",
    "    entropy = -1 * (num_pos/(num_pos+num_neg)*math.log(num_pos/(num_pos+num_neg)) + num_neg/(num_pos+num_neg)*math.log(num_neg/(num_pos+num_neg)))\n",
    "    #print(entropy)\n",
    "    #print(entropy*snr)\n",
    "    weights.append(entropy*snr)\n",
    "\n",
    "\n",
    "\n",
    "    minmax = MinMaxScaler(feature_range=(0, 1))  # 自动将dtype转换成float64\n",
    "    y_train_scores = minmax.fit_transform(y_train_scores.reshape(-1,1))\n",
    "\n",
    "    tmp_train_features = train_features\n",
    "    \n",
    "    \n",
    "    tmp = pd.DataFrame(y_train_scores)\n",
    "    tmp.columns = ['scores']\n",
    "    tmp = tmp.assign(bin_labels=pd.cut(tmp['scores'], [-1,0.2,0.4,0.6,0.8, float('inf')], labels=['bin0','bin1','bin2','bin3','bin4']))\n",
    "    train_data = tmp_train_features.reset_index()\n",
    "    train_data = pd.concat([train_data,train_labels],axis=1)\n",
    "    train_data = pd.concat([train_data,tmp],axis=1)\n",
    "    \n",
    "    counts = train_data['bin_labels'].value_counts()\n",
    "\n",
    "    bin0 = train_data.where(train_data['bin_labels']=='bin0').dropna()\n",
    "    bin1 = train_data.where(train_data['bin_labels']=='bin1').dropna()\n",
    "    bin2 = train_data.where(train_data['bin_labels']=='bin2').dropna()\n",
    "    bin3 = train_data.where(train_data['bin_labels']=='bin3').dropna()\n",
    "    bin4 = train_data.where(train_data['bin_labels']=='bin4').dropna()\n",
    "    \n",
    "\n",
    "    resample_data = bin4\n",
    "    resample_data = resample_data.drop(index=resample_data.index)\n",
    "\n",
    "    t_sum = 0\n",
    "    dis = []\n",
    "    for j in range(0,5):\n",
    "        t_sum += math.log(1/counts[j])\n",
    "    \n",
    "    for j in range(0,5):\n",
    "        # 超参：20\n",
    "        if int(negative_data.shape[0]*10*    (math.log(1/counts[j]) /t_sum)) > len(eval('bin' + str(j))):\n",
    "            resample_data.append(eval('bin' + str(j)))\n",
    "        else:\n",
    "            resample_data = resample_data.append(eval('bin' + str(j)).sample(int(negative_data.shape[0]*20*    (math.log(1/counts[j]) /t_sum)),replace=True))\n",
    "    \n",
    "\n",
    "    _train_labels = resample_data[['Class']]\n",
    "    _train_labels = _train_labels.append(negative_data[['Class']])\n",
    "    _train_features = resample_data.drop(columns=['Class','bin_labels','scores','index'])\n",
    "    _train_features = _train_features.append(negative_data.drop(columns=['Class']))\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth=10).fit(_train_features, _train_labels)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-Accuracy:0.9920529801324504\n",
      "my-Precision:0.8604651162790697\n",
      "my-Recall:1.0\n",
      "my-AUC:0.9958217270194987\n",
      "my-f1_score:0.9249999999999999\n"
     ]
    }
   ],
   "source": [
    "pro = [0 for index in range(0,len(test_labels))]\n",
    "\n",
    "num_model = 0\n",
    "total_weight = 0\n",
    "for model in models:\n",
    "    _predict_proba = model.predict_proba(test_features)\n",
    "    #print(_predict_proba)\n",
    "    for i in range(0,len(test_labels)):\n",
    "        pro[i] += _predict_proba[i][1]*weights[num_model]\n",
    "    \n",
    "    total_weight += weights[num_model]\n",
    "    num_model += 1\n",
    "\n",
    "    \n",
    "for i in range(0,len(test_labels)):\n",
    "    if pro[i]/total_weight>=0.5:\n",
    "        pro[i] = 1\n",
    "    else:\n",
    "        pro[i] = -1\n",
    "\n",
    "results = []\n",
    "_predict_labels = pro\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_labels, _predict_labels)\n",
    "precision = metrics.precision_score(test_labels,_predict_labels)\n",
    "recall = metrics.recall_score(test_labels,_predict_labels)\n",
    "f1_score = metrics.f1_score(test_labels,_predict_labels)\n",
    "roc_auc = metrics.roc_auc_score(test_labels, _predict_labels)\n",
    "\n",
    "print(\"my-Accuracy:\" + str(accuracy))\n",
    "print(\"my-Precision:\" + str(precision))\n",
    "print(\"my-Recall:\" + str(recall))\n",
    "print(\"my-AUC:\" + str(roc_auc))\n",
    "print(\"my-f1_score:\" + str(f1_score))\n",
    "results.append([\"my,\",accuracy,precision,recall,roc_auc,f1_score])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT-Accuracy:0.80622009569378\n",
      "DT-Precision:0.29207920792079206\n",
      "DT-Recall:0.7564102564102564\n",
      "DT-AUC:0.7838779514241255\n",
      "DT-f1_score:0.42142857142857143\n",
      "DT-Accuracy:0.8863636363636364\n",
      "DT-Precision:0.09523809523809523\n",
      "DT-Recall:0.02564102564102564\n",
      "DT-AUC:0.5002875312901698\n",
      "DT-f1_score:0.0404040404040404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-84-d549d4dc7f28>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model = se.RandomForestClassifier(max_depth=10).fit(_train_features, _train_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF-Accuracy:0.9055023923444976\n",
      "RF-Precision:0.4\n",
      "RF-Recall:0.02564102564102564\n",
      "RF-AUC:0.5108416209999322\n",
      "RF-f1_score:0.048192771084337345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT-Accuracy:0.8863636363636364\n",
      "GBDT-Precision:0.2702702702702703\n",
      "GBDT-Recall:0.1282051282051282\n",
      "GBDT-AUC:0.5462925377173399\n",
      "GBDT-f1_score:0.17391304347826086\n",
      "Adaboost-Accuracy:0.9055023923444976\n",
      "Adaboost-Precision:0.4\n",
      "GBAdaboostDT-Recall:0.02564102564102564\n",
      "Adaboost-AUC:0.5108416209999322\n",
      "Adaboost-f1_score:0.048192771084337345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPE-Accuracy:0.7942583732057417\n",
      "SPE-Precision:0.29914529914529914\n",
      "SPE-Recall:0.8974358974358975\n",
      "SPE-AUC:0.8405385291928827\n",
      "SPE-f1_score:0.44871794871794873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalanceCascade-Accuracy:0.6698564593301436\n",
      "BalanceCascade-Precision:0.19631901840490798\n",
      "BalanceCascade-Recall:0.8205128205128205\n",
      "BalanceCascade-AUC:0.7374331912590488\n",
      "BalanceCascade-f1_score:0.31683168316831684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imbalanced_ensemble\\ensemble\\under_sampling\\easy_ensemble.py:201: UserWarning: \n",
      "You are trying to set <class 'sklearn.tree._classes.DecisionTreeClassifier'> as the base estimator. A typical EasyEnsembleClassifier uses Adaboost as its base estimator, using other base estimators will degrades it to UnderBaggingClassifier.\n",
      "  warn(\n",
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EasyEnsemble-Accuracy:0.7858851674641149\n",
      "EasyEnsemble-Precision:0.29045643153526973\n",
      "EasyEnsemble-Recall:0.8974358974358975\n",
      "EasyEnsemble-AUC:0.8359211149448617\n",
      "EasyEnsemble-f1_score:0.438871473354232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSBoost-Accuracy:0.8098086124401914\n",
      "RUSBoost-Precision:0.20437956204379562\n",
      "RUSBoost-Recall:0.358974358974359\n",
      "RUSBoost-AUC:0.6075874433394223\n",
      "RUSBoost-f1_score:0.26046511627906976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTEBOOST-Accuracy:0.8696172248803827\n",
      "SMOTEBOOST-Precision:0.34951456310679613\n",
      "SMOTEBOOST-Recall:0.46153846153846156\n",
      "SMOTEBOOST-AUC:0.6865739801096002\n",
      "SMOTEBOOST-f1_score:0.3977900552486188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnderBagging-Accuracy:0.8026315789473685\n",
      "UnderBagging-Precision:0.3013698630136986\n",
      "UnderBagging-Recall:0.8461538461538461\n",
      "UnderBagging-AUC:0.822153440227319\n",
      "UnderBagging-f1_score:0.4444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNVS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverBagging-Accuracy:0.8995215311004785\n",
      "OverBagging-Precision:0.375\n",
      "OverBagging-Recall:0.11538461538461539\n",
      "OverBagging-AUC:0.5477978485894054\n",
      "OverBagging-f1_score:0.1764705882352941\n"
     ]
    }
   ],
   "source": [
    "def randomforest(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = se.RandomForestClassifier(max_depth=10).fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels,_predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels,_predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels,_predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "    print(\"RF-Accuracy:\" + str(accuracy))\n",
    "    print(\"RF-Precision:\" + str(precision))\n",
    "    print(\"RF-Recall:\" + str(recall))\n",
    "    print(\"RF-AUC:\" + str(roc_auc))\n",
    "    print(\"RF-f1_score:\" + str(f1_score))\n",
    "    ans = ['randomforest',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "def decisiontree(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = DecisionTreeClassifier(max_depth=10).fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels,_predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels,_predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels,_predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "\n",
    "    print(\"DT-Accuracy:\" + str(accuracy))\n",
    "    print(\"DT-Precision:\" + str(precision))\n",
    "    print(\"DT-Recall:\" + str(recall))\n",
    "    print(\"DT-AUC:\" + str(roc_auc))\n",
    "    print(\"DT-f1_score:\" + str(f1_score))\n",
    "    ans = ['decisiontree',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "\n",
    "def gbdt(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = GradientBoostingClassifier(max_depth=10).fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels, _predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels, _predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels, _predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "    report = metrics.classification_report(_test_labels, _predict_labels)\n",
    "    print(\"GBDT-Accuracy:\" + str(accuracy))\n",
    "    print(\"GBDT-Precision:\" + str(precision))\n",
    "    print(\"GBDT-Recall:\" + str(recall))\n",
    "    print(\"GBDT-AUC:\" + str(roc_auc))\n",
    "    print(\"GBDT-f1_score:\" + str(f1_score))\n",
    "    ans = ['GBDT',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "def adaboost(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = AdaBoostClassifier().fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels, _predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels, _predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels, _predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "    report = metrics.classification_report(_test_labels, _predict_labels)\n",
    "    print(\"Adaboost-Accuracy:\" + str(accuracy))\n",
    "    print(\"Adaboost-Precision:\" + str(precision))\n",
    "    print(\"GBAdaboostDT-Recall:\" + str(recall))\n",
    "    print(\"Adaboost-AUC:\" + str(roc_auc))\n",
    "    print(\"Adaboost-f1_score:\" + str(f1_score))\n",
    "    ans = ['adaboost',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "def SPE(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = SelfPacedEnsembleClassifier(base_estimator=DecisionTreeClassifier(max_depth=10)).fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels,_predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels,_predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels,_predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "\n",
    "    print(\"SPE-Accuracy:\" + str(accuracy))\n",
    "    print(\"SPE-Precision:\" + str(precision))\n",
    "    print(\"SPE-Recall:\" + str(recall))\n",
    "    print(\"SPE-AUC:\" + str(roc_auc))\n",
    "    print(\"SPE-f1_score:\" + str(f1_score))\n",
    "    ans = ['SPE',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "def BalanceCascade(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = BalanceCascadeClassifier(base_estimator=DecisionTreeClassifier(max_depth=10)).fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels, _predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels, _predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels, _predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "    report = metrics.classification_report(_test_labels, _predict_labels)\n",
    "    print(\"BalanceCascade-Accuracy:\" + str(accuracy))\n",
    "    print(\"BalanceCascade-Precision:\" + str(precision))\n",
    "    print(\"BalanceCascade-Recall:\" + str(recall))\n",
    "    print(\"BalanceCascade-AUC:\" + str(roc_auc))\n",
    "    print(\"BalanceCascade-f1_score:\" + str(f1_score))\n",
    "    ans = ['BalanceCascade',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "def EasyEnsemble(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = EasyEnsembleClassifier(base_estimator=DecisionTreeClassifier(max_depth=10)).fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels, _predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels, _predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels, _predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "    report = metrics.classification_report(_test_labels, _predict_labels)\n",
    "    print(\"EasyEnsemble-Accuracy:\" + str(accuracy))\n",
    "    print(\"EasyEnsemble-Precision:\" + str(precision))\n",
    "    print(\"EasyEnsemble-Recall:\" + str(recall))\n",
    "    print(\"EasyEnsemble-AUC:\" + str(roc_auc))\n",
    "    print(\"EasyEnsemble-f1_score:\" + str(f1_score))\n",
    "    ans = ['EasyEnsemble',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "def RUSBoost(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = RUSBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=10)).fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels, _predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels, _predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels, _predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "    report = metrics.classification_report(_test_labels, _predict_labels)\n",
    "    print(\"RUSBoost-Accuracy:\" + str(accuracy))\n",
    "    print(\"RUSBoost-Precision:\" + str(precision))\n",
    "    print(\"RUSBoost-Recall:\" + str(recall))\n",
    "    print(\"RUSBoost-AUC:\" + str(roc_auc))\n",
    "    print(\"RUSBoost-f1_score:\" + str(f1_score))\n",
    "    ans = ['RUSBoost',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "\n",
    "def SMOTEBOOST(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = SMOTEBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=10)).fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels, _predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels, _predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels, _predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "    report = metrics.classification_report(_test_labels, _predict_labels)\n",
    "    print(\"SMOTEBOOST-Accuracy:\" + str(accuracy))\n",
    "    print(\"SMOTEBOOST-Precision:\" + str(precision))\n",
    "    print(\"SMOTEBOOST-Recall:\" + str(recall))\n",
    "    print(\"SMOTEBOOST-AUC:\" + str(roc_auc))\n",
    "    print(\"SMOTEBOOST-f1_score:\" + str(f1_score))\n",
    "    ans = ['SMOTEBOOST',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "def UnderBagging(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = UnderBaggingClassifier().fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels, _predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels, _predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels, _predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "    report = metrics.classification_report(_test_labels, _predict_labels)\n",
    "    print(\"UnderBagging-Accuracy:\" + str(accuracy))\n",
    "    print(\"UnderBagging-Precision:\" + str(precision))\n",
    "    print(\"UnderBagging-Recall:\" + str(recall))\n",
    "    print(\"UnderBagging-AUC:\" + str(roc_auc))\n",
    "    print(\"UnderBagging-f1_score:\" + str(f1_score))\n",
    "    ans = ['UnderBagging',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "\n",
    "def OverBagging(_train_features, _train_labels, _test_features, _test_labels):\n",
    "    model = OverBaggingClassifier().fit(_train_features, _train_labels)\n",
    "    _predict_labels = model.predict(_test_features)\n",
    "    accuracy = metrics.accuracy_score(_test_labels, _predict_labels)\n",
    "    precision = metrics.precision_score(_test_labels, _predict_labels)\n",
    "    recall = metrics.recall_score(_test_labels, _predict_labels)\n",
    "    f1_score = metrics.f1_score(_test_labels, _predict_labels)\n",
    "    roc_auc = metrics.roc_auc_score(_test_labels, _predict_labels)\n",
    "    report = metrics.classification_report(_test_labels, _predict_labels)\n",
    "    print(\"OverBagging-Accuracy:\" + str(accuracy))\n",
    "    print(\"OverBagging-Precision:\" + str(precision))\n",
    "    print(\"OverBagging-Recall:\" + str(recall))\n",
    "    print(\"OverBagging-AUC:\" + str(roc_auc))\n",
    "    print(\"OverBagging-f1_score:\" + str(f1_score))\n",
    "    ans = ['OverBagging',accuracy,precision,recall,roc_auc,f1_score]\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results.append(decisiontree(train_features_res, train_labels_res, test_features, test_labels))\n",
    "\n",
    "\n",
    "results.append(decisiontree(train_features, train_labels, test_features, test_labels))\n",
    "results.append(randomforest(train_features, train_labels, test_features, test_labels))\n",
    "results.append(gbdt(train_features, train_labels, test_features, test_labels))\n",
    "results.append(adaboost(train_features, train_labels, test_features, test_labels))\n",
    "results.append(SPE(train_features, train_labels, test_features, test_labels))\n",
    "results.append(BalanceCascade(train_features, train_labels, test_features, test_labels))\n",
    "results.append(EasyEnsemble(train_features, train_labels, test_features, test_labels))\n",
    "results.append(RUSBoost(train_features, train_labels, test_features, test_labels))\n",
    "results.append(SMOTEBOOST(train_features, train_labels, test_features, test_labels))\n",
    "results.append(UnderBagging(train_features, train_labels, test_features, test_labels))\n",
    "results.append(OverBagging(train_features, train_labels, test_features, test_labels))\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(\"abalone.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9813c9b79aee7cf90f10982e262a575dfd4850f1243c3c5f011d24e4ac84e9d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('UNVS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
